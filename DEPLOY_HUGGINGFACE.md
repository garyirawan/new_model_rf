# ğŸš€ Checklist Deploy ke Hugging Face Spaces

## âœ… File yang Sudah Siap

### 1. **requirements.txt** âœ…
```
fastapi==0.114.2       â† Match dengan environment VSCode
uvicorn[standard]==0.30.6
pydantic==2.8.2
scikit-learn==1.7.2    â† Match dengan environment VSCode
numpy==2.3.4           â† Match dengan environment VSCode
joblib==1.5.2          â† Match dengan environment VSCode
python-multipart==0.0.20
```

### 2. **Dockerfile** âœ…
- Base image: `python:3.11-slim`
- Port: `7860` (Hugging Face default)
- Health check: Sudah ditambahkan
- Environment variables: Sudah diset
- Optimized layer caching
- Copy only necessary files

### 3. **.dockerignore** âœ…
- Exclude frontend files (React/Vite)
- Exclude test files
- Exclude .git, .env
- Exclude deployment scripts
- Exclude Arduino/ESP32 files
- **INCLUDE**: backend_fastapi.py, inference_rf.py, model files

### 4. **README_HF.md** âœ…
- Markdown header dengan metadata Hugging Face
- API documentation
- Example usage
- Model information
- Thresholds table

### 5. **Backend Files** âœ…
- `backend_fastapi.py` - Main API âœ…
- `inference_rf.py` - ML inference logic âœ…
- `rf_total_coliform_log1p_improved.joblib` - Model file âœ…
- `model_features_order.txt` - Feature order âœ…

---

## ğŸ“¦ File yang Akan Di-Push ke Hugging Face

```
water-quality-ai/  (Hugging Face Space)
â”œâ”€â”€ Dockerfile                                    â† Deploy configuration
â”œâ”€â”€ README.md                                     â† Rename README_HF.md â†’ README.md
â”œâ”€â”€ requirements.txt                              â† Python dependencies
â”œâ”€â”€ backend_fastapi.py                            â† Main API
â”œâ”€â”€ inference_rf.py                               â† ML logic
â”œâ”€â”€ rf_total_coliform_log1p_improved.joblib      â† Model (100MB+)
â””â”€â”€ model_features_order.txt                      â† Feature order
```

**TIDAK PERLU:**
- âŒ app.py (Dockerfile langsung run backend_fastapi.py)
- âŒ Frontend files (React/TypeScript)
- âŒ Test files
- âŒ ESP32 Arduino files
- âŒ Deploy scripts (deploy.sh, deploy.ps1)

---

## ğŸš€ Langkah Deploy

### Step 1: Persiapan File âœ… DONE
- [x] Update requirements.txt dengan versi yang match
- [x] Optimize Dockerfile
- [x] Update .dockerignore
- [x] Buat README_HF.md

### Step 2: Buat Space di Hugging Face âœ… DONE (by User)
- [x] Space name: `water-quality-ai`
- [x] SDK: Docker
- [x] Hardware: CPU basic (FREE)
- [x] Visibility: Public/Private

### Step 3: Clone Space ke Local
```bash
# Install git-lfs (jika belum)
git lfs install

# Clone Hugging Face Space
git clone https://huggingface.co/spaces/YOUR_USERNAME/water-quality-ai
cd water-quality-ai
```

### Step 4: Copy File yang Diperlukan
```bash
# From your project folder, copy these files:
cp backend_fastapi.py water-quality-ai/
cp inference_rf.py water-quality-ai/
cp rf_total_coliform_log1p_improved.joblib water-quality-ai/
cp model_features_order.txt water-quality-ai/
cp Dockerfile water-quality-ai/
cp requirements.txt water-quality-ai/

# Rename README for Hugging Face
cp README_HF.md water-quality-ai/README.md
```

### Step 5: Push ke Hugging Face
```bash
cd water-quality-ai

# Add all files
git add .

# Commit
git commit -m "Initial deploy: Water Quality AI API with Random Forest model"

# Push ke Hugging Face (akan trigger auto-build)
git push origin main
```

### Step 6: Tunggu Build (5-10 menit)
- Hugging Face akan build Docker image
- Install dependencies dari requirements.txt
- Start uvicorn server di port 7860
- Status bisa dicek di tab "Logs"

### Step 7: Test API
```bash
# Test endpoint
curl https://huggingface.co/spaces/YOUR_USERNAME/water-quality-ai/docs

# Test prediction
curl -X POST "https://YOUR_USERNAME-water-quality-ai.hf.space/predict" \
  -H "Content-Type: application/json" \
  -d '{"temp_c": 27, "do_mgl": 7, "ph": 7.5, "conductivity_uscm": 300}'
```

---

## âš ï¸ Troubleshooting

### Build Failed?
- **Check Logs**: Tab "Logs" di Hugging Face Space
- **Common issues**:
  - Missing dependencies â†’ Update requirements.txt
  - Large model file â†’ Use git-lfs
  - Port conflict â†’ Pastikan Dockerfile expose 7860

### Model File Too Large?
```bash
# Track model file dengan git-lfs
git lfs track "*.joblib"
git add .gitattributes
git add rf_total_coliform_log1p_improved.joblib
git commit -m "Track model with git-lfs"
git push
```

### API Timeout?
- Upgrade Space hardware (CPU basic â†’ CPU boost)
- Optimize model loading
- Add caching

---

## ğŸ”„ Update Frontend untuk Connect ke HF

Setelah backend deploy, update frontend:

```typescript
// frontend_water_quality_dashboard_react.tsx
const API_BASE = import.meta.env.VITE_API_BASE || 
  "https://YOUR_USERNAME-water-quality-ai.hf.space";
```

---

## ğŸ“Š Estimasi Biaya

- **CPU basic (FREE)**: 
  - âœ… 2 CPU cores
  - âœ… 16GB RAM
  - âœ… Unlimited usage untuk public spaces
  - âš ï¸ Auto-sleep setelah 48 jam idle (akan wake saat request)

- **CPU boost ($0.50/hr)**:
  - Jika perlu always-on
  - Lebih cepat inference

---

## âœ… Ready to Deploy!

Semua file sudah siap. Tinggal ikuti Step 3-7 di atas! ğŸš€
